{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "T tests"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "2 sided T test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drow two INDEPENDENT samples from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardDerivation = 10\n",
    "mean = 5\n",
    "size = 500\n",
    "\n",
    "rvs1 = stats.norm.rvs(loc=mean, scale=standardDerivation, size=size)\n",
    "rvs2 = stats.norm.rvs(loc=mean, scale=standardDerivation, size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a two-sided test for the null hypothesis that 2 independent samples have identical average (expected) values. This test assumes that the populations have identical variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.26833823296238857, pvalue=0.78849443369565098)"
      ]
     },
     "execution_count": 4,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "stats.ttest_ind(rvs1, rvs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If equal_var=False, perform Welch’s t-test, which does not assume equal population variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(rvs1, rvs2, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assume threshold=0.1 we clearly see that base on this test we can not reject null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets drow from distribution with different variance and the same mean and take advantege of the fact that we can use Welch’s t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.46580283298287956, pvalue=0.64149646246568737)"
      ]
     },
     "execution_count": 6,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "standardDerivation = 20\n",
    "mean = 5\n",
    "\n",
    "rvs3 = stats.norm.rvs(loc=mean, scale=standardDerivation, size=size)\n",
    "stats.ttest_ind(rvs1, rvs3, equal_var = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see last test is robust on difference of variances. As we expected pi value is much above threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get quite unsatifying results for small unequal samples for both tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.7826177481118779, pvalue=0.0055624972754207335)"
      ]
     },
     "execution_count": 7,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "rvs1 = stats.norm.rvs(loc=5, scale=10, size=500)\n",
    "rvs5 = stats.norm.rvs(loc=8, scale=20, size=100)\n",
    "\n",
    "stats.ttest_ind(rvs1, rvs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.804532802749901, pvalue=0.073915180041047482)"
      ]
     },
     "execution_count": 8,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "stats.ttest_ind(rvs1, rvs5, equal_var = False)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "One sample 2 sided T test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a two-sided test for the null hypothesis that the expected value (mean) of a sample of independent observations a is equal to the given population mean, popmean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_1samp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resouces https://www.udacity.com/course/viewer#!/c-ud359/l-649959144/m-638170789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Welch%27s_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A normal continuous random variable.\n\n    The location (loc) keyword specifies the mean.\n    The scale (scale) keyword specifies the standard deviation.\n\n    As an instance of the `rv_continuous` class, `norm` object inherits from it\n    a collection of generic methods (see below for the full list),\n    and completes them with details specific for this particular distribution.\n    \n    Methods\n    -------\n    ``rvs(loc=0, scale=1, size=1, random_state=None)``\n        Random variates.\n    ``pdf(x, loc=0, scale=1)``\n        Probability density function.\n    ``logpdf(x, loc=0, scale=1)``\n        Log of the probability density function.\n    ``cdf(x, loc=0, scale=1)``\n        Cumulative density function.\n    ``logcdf(x, loc=0, scale=1)``\n        Log of the cumulative density function.\n    ``sf(x, loc=0, scale=1)``\n        Survival function  (also defined as ``1 - cdf``, but `sf` is sometimes more accurate).\n    ``logsf(x, loc=0, scale=1)``\n        Log of the survival function.\n    ``ppf(q, loc=0, scale=1)``\n        Percent point function (inverse of ``cdf`` --- percentiles).\n    ``isf(q, loc=0, scale=1)``\n        Inverse survival function (inverse of ``sf``).\n    ``moment(n, loc=0, scale=1)``\n        Non-central moment of order n\n    ``stats(loc=0, scale=1, moments='mv')``\n        Mean('m'), variance('v'), skew('s'), and/or kurtosis('k').\n    ``entropy(loc=0, scale=1)``\n        (Differential) entropy of the RV.\n    ``fit(data, loc=0, scale=1)``\n        Parameter estimates for generic data.\n    ``expect(func, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)``\n        Expected value of a function (of one argument) with respect to the distribution.\n    ``median(loc=0, scale=1)``\n        Median of the distribution.\n    ``mean(loc=0, scale=1)``\n        Mean of the distribution.\n    ``var(loc=0, scale=1)``\n        Variance of the distribution.\n    ``std(loc=0, scale=1)``\n        Standard deviation of the distribution.\n    ``interval(alpha, loc=0, scale=1)``\n        Endpoints of the range that contains alpha percent of the distribution\n\n    Notes\n    -----\n    The probability density function for `norm` is::\n\n        norm.pdf(x) = exp(-x**2/2)/sqrt(2*pi)\n\n    The probability density above is defined in the \"standardized\" form. To shift\n    and/or scale the distribution use the ``loc`` and ``scale`` parameters.\n    Specifically, ``norm.pdf(x, loc, scale)`` is identically\n    equivalent to ``norm.pdf(y) / scale`` with\n    ``y = (x - loc) / scale``.\n\n    Examples\n    --------\n    >>> from scipy.stats import norm\n    >>> import matplotlib.pyplot as plt\n    >>> fig, ax = plt.subplots(1, 1)\n    \n    Calculate a few first moments:\n    \n    \n    >>> mean, var, skew, kurt = norm.stats(moments='mvsk')\n    \n    Display the probability density function (``pdf``):\n    \n    >>> x = np.linspace(norm.ppf(0.01),\n    ...                 norm.ppf(0.99), 100)\n    >>> ax.plot(x, norm.pdf(x),\n    ...        'r-', lw=5, alpha=0.6, label='norm pdf')\n    \n    Alternatively, the distribution object can be called (as a function)\n    to fix the shape, location and scale parameters. This returns a \"frozen\"\n    RV object holding the given parameters fixed. \n    \n    Freeze the distribution and display the frozen ``pdf``:\n    \n    >>> rv = norm()\n    >>> ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n    \n    Check accuracy of ``cdf`` and ``ppf``:\n    \n    >>> vals = norm.ppf([0.001, 0.5, 0.999])\n    >>> np.allclose([0.001, 0.5, 0.999], norm.cdf(vals))\n    True\n    \n    Generate random numbers:\n    \n    >>> r = norm.rvs(size=1000)\n    \n    And compare the histogram:\n    \n    >>> ax.hist(r, normed=True, histtype='stepfilled', alpha=0.2)\n    >>> ax.legend(loc='best', frameon=False)\n    >>> plt.show()\n    \n\n    \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "print(norm.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tester', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_binned_statistic', '_constants', '_continuous_distns', '_discrete_distns', '_distn_infrastructure', '_distr_params', '_multivariate', '_rank', '_stats_mstats_common', '_tukeylambda_stats', 'absolute_import', 'alpha', 'anderson', 'anderson_ksamp', 'anglit', 'ansari', 'arcsine', 'bartlett', 'bayes_mvs', 'bernoulli', 'beta', 'betai', 'betaprime', 'binned_statistic', 'binned_statistic_2d', 'binned_statistic_dd', 'binom', 'binom_test', 'boltzmann', 'boxcox', 'boxcox_llf', 'boxcox_normmax', 'boxcox_normplot', 'bradford', 'burr', 'cauchy', 'chi', 'chi2', 'chi2_contingency', 'chisqprob', 'chisquare', 'circmean', 'circstd', 'circvar', 'combine_pvalues', 'contingency', 'cosine', 'cumfreq', 'describe', 'dgamma', 'dirichlet', 'distributions', 'division', 'dlaplace', 'dweibull', 'entropy', 'erlang', 'expon', 'exponnorm', 'exponpow', 'exponweib', 'f', 'f_oneway', 'f_value', 'f_value_multivariate', 'f_value_wilks_lambda', 'fastsort', 'fatiguelife', 'find_repeats', 'fisher_exact', 'fisk', 'fligner', 'foldcauchy', 'foldnorm', 'frechet_l', 'frechet_r', 'friedmanchisquare', 'gamma', 'gausshyper', 'gaussian_kde', 'genexpon', 'genextreme', 'gengamma', 'genhalflogistic', 'genlogistic', 'gennorm', 'genpareto', 'geom', 'gilbrat', 'gmean', 'gompertz', 'gumbel_l', 'gumbel_r', 'halfcauchy', 'halfgennorm', 'halflogistic', 'halfnorm', 'histogram', 'histogram2', 'hmean', 'hypergeom', 'hypsecant', 'invgamma', 'invgauss', 'invweibull', 'invwishart', 'itemfreq', 'jarque_bera', 'johnsonsb', 'johnsonsu', 'kde', 'kendalltau', 'kruskal', 'ks_2samp', 'ksone', 'kstat', 'kstatvar', 'kstest', 'kstwobign', 'kurtosis', 'kurtosistest', 'laplace', 'levene', 'levy', 'levy_l', 'levy_stable', 'linregress', 'loggamma', 'logistic', 'loglaplace', 'lognorm', 'logser', 'lomax', 'mannwhitneyu', 'matrix_normal', 'maxwell', 'median_test', 'mielke', 'mode', 'moment', 'mood', 'morestats', 'mstats', 'mstats_basic', 'mstats_extras', 'multivariate_normal', 'mvn', 'mvsdist', 'nakagami', 'nanmean', 'nanmedian', 'nanstd', 'nbinom', 'ncf', 'nct', 'ncx2', 'norm', 'normaltest', 'obrientransform', 'pareto', 'pdf_fromgamma', 'pearson3', 'pearsonr', 'percentileofscore', 'planck', 'pointbiserialr', 'poisson', 'power_divergence', 'powerlaw', 'powerlognorm', 'powernorm', 'ppcc_max', 'ppcc_plot', 'print_function', 'probplot', 'randint', 'rankdata', 'ranksums', 'rayleigh', 'rdist', 'recipinvgauss', 'reciprocal', 'relfreq', 'rice', 'rv_continuous', 'rv_discrete', 'scoreatpercentile', 'sem', 'semicircular', 'shapiro', 'sigmaclip', 'signaltonoise', 'skellam', 'skew', 'skewtest', 'spearmanr', 'square_of_sums', 'ss', 'statlib', 'stats', 't', 'test', 'theilslopes', 'threshold', 'tiecorrect', 'tmax', 'tmean', 'tmin', 'triang', 'trim1', 'trim_mean', 'trimboth', 'truncexpon', 'truncnorm', 'tsem', 'tstd', 'ttest_1samp', 'ttest_ind', 'ttest_ind_from_stats', 'ttest_rel', 'tukeylambda', 'tvar', 'uniform', 'variation', 'vonmises', 'vonmises_cython', 'vonmises_line', 'wald', 'weibull_max', 'weibull_min', 'wilcoxon', 'wishart', 'wrapcauchy', 'zipf', 'zmap', 'zscore']\n"
     ]
    }
   ],
   "source": [
    "print(dir(stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A uniform continuous random variable.\n\n    This distribution is constant between `loc` and ``loc + scale``.\n\n    As an instance of the `rv_continuous` class, `uniform` object inherits from it\n    a collection of generic methods (see below for the full list),\n    and completes them with details specific for this particular distribution.\n    \n    Methods\n    -------\n    ``rvs(loc=0, scale=1, size=1, random_state=None)``\n        Random variates.\n    ``pdf(x, loc=0, scale=1)``\n        Probability density function.\n    ``logpdf(x, loc=0, scale=1)``\n        Log of the probability density function.\n    ``cdf(x, loc=0, scale=1)``\n        Cumulative density function.\n    ``logcdf(x, loc=0, scale=1)``\n        Log of the cumulative density function.\n    ``sf(x, loc=0, scale=1)``\n        Survival function  (also defined as ``1 - cdf``, but `sf` is sometimes more accurate).\n    ``logsf(x, loc=0, scale=1)``\n        Log of the survival function.\n    ``ppf(q, loc=0, scale=1)``\n        Percent point function (inverse of ``cdf`` --- percentiles).\n    ``isf(q, loc=0, scale=1)``\n        Inverse survival function (inverse of ``sf``).\n    ``moment(n, loc=0, scale=1)``\n        Non-central moment of order n\n    ``stats(loc=0, scale=1, moments='mv')``\n        Mean('m'), variance('v'), skew('s'), and/or kurtosis('k').\n    ``entropy(loc=0, scale=1)``\n        (Differential) entropy of the RV.\n    ``fit(data, loc=0, scale=1)``\n        Parameter estimates for generic data.\n    ``expect(func, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)``\n        Expected value of a function (of one argument) with respect to the distribution.\n    ``median(loc=0, scale=1)``\n        Median of the distribution.\n    ``mean(loc=0, scale=1)``\n        Mean of the distribution.\n    ``var(loc=0, scale=1)``\n        Variance of the distribution.\n    ``std(loc=0, scale=1)``\n        Standard deviation of the distribution.\n    ``interval(alpha, loc=0, scale=1)``\n        Endpoints of the range that contains alpha percent of the distribution\n\n    Examples\n    --------\n    >>> from scipy.stats import uniform\n    >>> import matplotlib.pyplot as plt\n    >>> fig, ax = plt.subplots(1, 1)\n    \n    Calculate a few first moments:\n    \n    \n    >>> mean, var, skew, kurt = uniform.stats(moments='mvsk')\n    \n    Display the probability density function (``pdf``):\n    \n    >>> x = np.linspace(uniform.ppf(0.01),\n    ...                 uniform.ppf(0.99), 100)\n    >>> ax.plot(x, uniform.pdf(x),\n    ...        'r-', lw=5, alpha=0.6, label='uniform pdf')\n    \n    Alternatively, the distribution object can be called (as a function)\n    to fix the shape, location and scale parameters. This returns a \"frozen\"\n    RV object holding the given parameters fixed. \n    \n    Freeze the distribution and display the frozen ``pdf``:\n    \n    >>> rv = uniform()\n    >>> ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n    \n    Check accuracy of ``cdf`` and ``ppf``:\n    \n    >>> vals = uniform.ppf([0.001, 0.5, 0.999])\n    >>> np.allclose([0.001, 0.5, 0.999], uniform.cdf(vals))\n    True\n    \n    Generate random numbers:\n    \n    >>> r = uniform.rvs(size=1000)\n    \n    And compare the histogram:\n    \n    >>> ax.hist(r, normed=True, histtype='stepfilled', alpha=0.2)\n    >>> ax.legend(loc='best', frameon=False)\n    >>> plt.show()\n    \n\n    \n"
     ]
    }
   ],
   "source": [
    "print(stats.uniform.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}